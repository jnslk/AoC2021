{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "colored-differential",
   "metadata": {},
   "source": [
    "# Advent of Code\n",
    "\n",
    "This notebook contains my solutions for the 2021 version of [Advent of Code](https://adventofcode.com/2021).\n",
    "\n",
    "![Test Notebook](https://github.com/jnslk/AoC2021/workflows/test%20notebook/badge.svg)\n",
    "\n",
    "\n",
    "## Imports and Dataimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "strong-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, deque, defaultdict\n",
    "from statistics import median, mean\n",
    "from math import floor, ceil\n",
    "from typing import Tuple, Set, cast, List\n",
    "import re\n",
    "\n",
    "def data(day: int, parser=str, sep='\\n') -> list:\n",
    "    \"Split the day's input file into sections separated by `sep`, and apply `parser` function to each.\"\n",
    "    with open(f'../data/day{day}.txt') as f:\n",
    "        sections = f.read().rstrip().split(sep)\n",
    "        return list(map(parser, sections))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-incentive",
   "metadata": {},
   "source": [
    "# Day 1: Sonar Sweep\n",
    "\n",
    "## Part 1\n",
    "For the first puzzle we are provided with a list of depth measurements from sonar. The task is to count the number of depth measurements that are greater than the previously measured value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-lunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_1_input = '''199\n",
    "200\n",
    "208\n",
    "210\n",
    "200\n",
    "207\n",
    "240\n",
    "269\n",
    "260\n",
    "263'''\n",
    "\n",
    "test1_1_output = 7\n",
    "\n",
    "def deeper(measurements):\n",
    "    count = 0\n",
    "    for i, depth in enumerate(measurements[1:]):\n",
    "        if depth > measurements[i]:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "assert deeper([*map(int, test1_1_input.split())]) == test1_1_output\n",
    "\n",
    "input1 = data(1, int)\n",
    "deeper(input1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-contribution",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "The second part of the challenge is to use a sliding window of 3 measurements summed together and count the number of times when the measurements in this sliding window are greater than the previous sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_2_output = 5\n",
    "\n",
    "def deeper_sliding_window(measurements):\n",
    "    count = 0\n",
    "    for i, depth in enumerate(measurements[3:]):\n",
    "        if depth + measurements[i+1] + measurements[i+2] > sum(measurements[i:i+3]):\n",
    "            count += 1          \n",
    "    return count\n",
    "\n",
    "assert deeper_sliding_window([*map(int, test1_1_input.split())]) == test1_2_output\n",
    "\n",
    "input1 = data(1, int)\n",
    "deeper_sliding_window(input1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-workplace",
   "metadata": {},
   "source": [
    "# Day 2: Dive!\n",
    "\n",
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-electronics",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_1_input = '''forward 5\n",
    "down 5\n",
    "forward 8\n",
    "up 3\n",
    "down 8\n",
    "forward 2'''\n",
    "\n",
    "test2_1_output = 150\n",
    "\n",
    "def parse_course(line) -> (str, int):\n",
    "    return line.split()[0], int(line.split()[1])\n",
    "\n",
    "def follow_course(course) -> int:\n",
    "    distance = 0\n",
    "    depth = 0\n",
    "    for instruction, value in course:\n",
    "        if instruction == 'forward':\n",
    "            distance += value\n",
    "        elif instruction == 'down':\n",
    "            depth += value\n",
    "        else:\n",
    "            depth -= value\n",
    "    return distance * depth\n",
    "\n",
    "assert follow_course([*map(parse_course, test2_1_input.split('\\n'))]) == test2_1_output\n",
    "\n",
    "input2 = data(2, parse_course)\n",
    "\n",
    "follow_course(input2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-processor",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-schedule",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_2_output = 900\n",
    "\n",
    "def follow_complex_course(course) -> int:\n",
    "    distance = 0\n",
    "    depth = 0\n",
    "    aim = 0\n",
    "    for instruction, value in course:\n",
    "        if instruction == 'forward':\n",
    "            distance += value\n",
    "            depth += (aim * value)\n",
    "        elif instruction == 'down':\n",
    "            aim += value\n",
    "        else:\n",
    "            aim -= value\n",
    "    return distance * depth\n",
    "\n",
    "assert follow_complex_course([*map(parse_course, test2_1_input.split('\\n'))]) == test2_2_output\n",
    "\n",
    "input2 = data(2, parse_course)\n",
    "\n",
    "follow_complex_course(input2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-constant",
   "metadata": {},
   "source": [
    "# Day 3: Binary Diagnostic\n",
    "\n",
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-virtue",
   "metadata": {},
   "outputs": [],
   "source": [
    "test3_1_input = '''00100\n",
    "11110\n",
    "10110\n",
    "10111\n",
    "10101\n",
    "01111\n",
    "00111\n",
    "11100\n",
    "10000\n",
    "11001\n",
    "00010\n",
    "01010'''\n",
    "\n",
    "test3_1_output = 198\n",
    "\n",
    "def check_power_consumption(binary_data) -> int:\n",
    "    counter = [0] * len(binary_data[0])\n",
    "    treshold = (len(binary_data) / 2)\n",
    "    for line in binary_data:\n",
    "        for i, digit in enumerate(line):\n",
    "            if digit == '1':\n",
    "                counter[i] += 1\n",
    "    gamma = [0] * len(counter)\n",
    "    for i in range(len(gamma)):\n",
    "        if counter[i] > treshold:\n",
    "            gamma[i] = 1\n",
    "    epsilon = [0] * len(gamma)\n",
    "    for i in range(len(epsilon)):\n",
    "        if gamma[i] == 1:\n",
    "            epsilon[i] = 0\n",
    "        else:\n",
    "            epsilon[i] = 1\n",
    "    \n",
    "    gamma = int(''.join(map(str, gamma)), 2)\n",
    "    epsilon = int(''.join(map(str, epsilon)), 2)\n",
    "    return gamma * epsilon\n",
    "\n",
    "assert check_power_consumption(test3_1_input.split()) == test3_1_output\n",
    "\n",
    "input3 = data(3)\n",
    "\n",
    "check_power_consumption(input3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-switzerland",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "test3_2_output = 230\n",
    "\n",
    "def verify_life_support_rating(binary_data) -> int:\n",
    "    oxygen_candidates = binary_data\n",
    "    co2_candidates = binary_data\n",
    "    counter = [0] * len(binary_data[0])\n",
    "    for i in range(len(counter)):\n",
    "        for line in oxygen_candidates:\n",
    "            if line[i] == '1':\n",
    "                counter[i] += 1\n",
    "        if len(oxygen_candidates) > 1:\n",
    "            oxygen_treshold = len(oxygen_candidates) / 2\n",
    "            if counter[i] >= oxygen_treshold:\n",
    "                oxygen_target = '1'\n",
    "            else:\n",
    "                oxygen_target = '0'\n",
    "            oxygen_candidates = [x for x in oxygen_candidates if x[i] == oxygen_target]\n",
    "        counter[i] = 0\n",
    "        for line in co2_candidates:\n",
    "            if line[i] == '1':\n",
    "                counter[i] += 1\n",
    "        if len(co2_candidates) > 1:\n",
    "            co2_treshold = len(co2_candidates) / 2\n",
    "            if counter[i] >= co2_treshold:\n",
    "                co2_target = '0'\n",
    "            else:\n",
    "                co2_target = '1'\n",
    "            co2_candidates = [x for x in co2_candidates if x[i] == co2_target]\n",
    "    \n",
    "    \n",
    "    oxygen = int(''.join(map(str, oxygen_candidates)), 2)\n",
    "    co2 = int(''.join(map(str, co2_candidates)), 2)\n",
    "    \n",
    "    return oxygen * co2\n",
    "\n",
    "assert verify_life_support_rating(test3_1_input.split()) == test3_2_output\n",
    "\n",
    "verify_life_support_rating(input3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-officer",
   "metadata": {},
   "source": [
    "# Day 4: Giant Squid\n",
    "\n",
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-participation",
   "metadata": {},
   "outputs": [],
   "source": [
    "test4_1_input = '''7,4,9,5,11,17,23,2,0,14,21,24,10,16,13,6,15,25,12,22,18,20,8,19,3,26,1\n",
    "\n",
    "22 13 17 11  0\n",
    " 8  2 23  4 24\n",
    "21  9 14 16  7\n",
    " 6 10  3 18  5\n",
    " 1 12 20 15 19\n",
    "\n",
    " 3 15  0  2 22\n",
    " 9 18 13 17  5\n",
    "19  8  7 25 23\n",
    "20 11 10 24  4\n",
    "14 21 16 12  6\n",
    "\n",
    "14 21 17 24  4\n",
    "10 16 15  9 19\n",
    "18  8 23 26 20\n",
    "22 11 13  6  5\n",
    " 2  0 12  3  7'''\n",
    "\n",
    "test4_1_output = 4512\n",
    "\n",
    "def parse_boards(boards):\n",
    "    all_boards = []\n",
    "    for board in boards:\n",
    "        b = []\n",
    "        b.append(set([*map(int, board[:5])]))\n",
    "        b.append(set([*map(int, board[5:10])]))\n",
    "        b.append(set([*map(int, board[10:15])]))\n",
    "        b.append(set([*map(int, board[15:20])]))\n",
    "        b.append(set([*map(int, board[20:25])]))\n",
    "        b.append(set([*map(int, board[::5])]))\n",
    "        b.append(set([*map(int, board[1::5])]))\n",
    "        b.append(set([*map(int, board[2::5])]))\n",
    "        b.append(set([*map(int, board[3::5])]))\n",
    "        b.append(set([*map(int, board[4::5])]))\n",
    "        all_boards.append(b)\n",
    "    return all_boards\n",
    "\n",
    "def winning_board_score(numbers, boards) -> int:\n",
    "    for num in numbers:\n",
    "        for board in boards:\n",
    "            for rowcol in board:\n",
    "                rowcol.discard(num)\n",
    "                if len(rowcol) == 0:\n",
    "                    score = sum([*map(sum,(board[:5]))])\n",
    "                    return score * num\n",
    "\n",
    "test_nums = [*map(int,test4_1_input.split('\\n\\n')[0].split(','))]\n",
    "test_boards = [*map(str.split,test4_1_input.split('\\n\\n')[1:])]\n",
    "assert winning_board_score(test_nums, parse_boards(test_boards))\n",
    "\n",
    "input4 = data(4, sep='\\n\\n')\n",
    "nums = [*map(int, input4[0].split(','))]\n",
    "boards = [*map(str.split, input4[1:])]\n",
    "\n",
    "winning_board_score(nums, parse_boards(boards))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-publication",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-method",
   "metadata": {},
   "outputs": [],
   "source": [
    "test4_2_output = 1924\n",
    "\n",
    "def last_board_score(numbers, boards) -> int:\n",
    "    winning_boards = set()\n",
    "    for num in numbers:\n",
    "        for i, board in enumerate(boards):\n",
    "            for rowcol in board:\n",
    "                rowcol.discard(num)\n",
    "                if len(rowcol) == 0:\n",
    "                    winning_boards.add(i)\n",
    "                    if len(winning_boards) == len(boards):\n",
    "                        score = sum([*map(sum,(board[:5]))])\n",
    "                        return score * num \n",
    "\n",
    "\n",
    "assert last_board_score(test_nums, parse_boards(test_boards)) == test4_2_output\n",
    "\n",
    "input4 = data(4, sep='\\n\\n')\n",
    "nums = [*map(int, input4[0].split(','))]\n",
    "boards = [*map(str.split, input4[1:])]\n",
    "\n",
    "last_board_score(nums, parse_boards(boards))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-abortion",
   "metadata": {},
   "source": [
    "# Day 5: Hydrothermal Venture\n",
    "\n",
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adverse-ground",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7297"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test5_1_input = '''0,9 -> 5,9\n",
    "8,0 -> 0,8\n",
    "9,4 -> 3,4\n",
    "2,2 -> 2,1\n",
    "7,0 -> 7,4\n",
    "6,4 -> 2,0\n",
    "0,9 -> 2,9\n",
    "3,4 -> 1,4\n",
    "0,0 -> 8,8\n",
    "5,5 -> 8,2'''\n",
    "\n",
    "test5_1_output = 5\n",
    "\n",
    "def parse_lines(line):\n",
    "    first, second = line.split(' -> ')\n",
    "    first = first.split(',')\n",
    "    second = second.split(',')\n",
    "    return [*map(int,first)], [*map(int,second)]\n",
    "\n",
    "def count_overlapping_lines(points) -> int:\n",
    "    overlapping = Counter()\n",
    "    for pair in points:\n",
    "        x1, y1 = pair[0]\n",
    "        x2, y2 = pair[1]\n",
    "        if x1 == x2 or y1 == y2:\n",
    "            for x in range(min(x1,x2),max(x1,x2)+1):\n",
    "                for y in range(min(y1,y2),max(y1,y2)+1):\n",
    "                    overlapping[(x,y)] += 1\n",
    "    return sum(1 for v in overlapping.values() if v > 1)\n",
    "\n",
    "assert count_overlapping_lines([*map(parse_lines, test5_1_input.split('\\n'))]) == test5_1_output\n",
    "\n",
    "input5 = data(5, parse_lines)\n",
    "\n",
    "count_overlapping_lines(input5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educational-blanket",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "prescription-lecture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21038"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test5_2_output = 12\n",
    "\n",
    "def count_overlapping_lines_diagonal(points) -> int:\n",
    "    overlapping = Counter()\n",
    "    for pair in points:\n",
    "        x1, y1 = pair[0]\n",
    "        x2, y2 = pair[1]\n",
    "        dx = 1 if x2>x1 else -1\n",
    "        dy = 1 if y2>y1 else -1\n",
    "        if x1 == x2:\n",
    "            dx = 0\n",
    "        if y1 == y2:\n",
    "            dy = 0\n",
    "        overlapping[(x1,y1)] += 1\n",
    "        while x1 != x2 or y1 != y2:\n",
    "            x1 += dx\n",
    "            y1 += dy\n",
    "            overlapping[(x1,y1)] += 1\n",
    "    return  sum(1 for v in overlapping.values() if v > 1)\n",
    "\n",
    "assert count_overlapping_lines_diagonal([*map(parse_lines, test5_1_input.split('\\n'))]) == test5_2_output\n",
    "\n",
    "input5 = data(5, parse_lines)\n",
    "\n",
    "count_overlapping_lines_diagonal(input5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-leadership",
   "metadata": {},
   "source": [
    "# Day 6: Lanternfish\n",
    "\n",
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "verbal-expansion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373378"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test6_1_input = '3,4,3,1,2'\n",
    "\n",
    "test6_1_output1 = 26\n",
    "test6_1_output2 = 5934\n",
    "\n",
    "def simulate_lanternfish(fish, n=80) -> int:\n",
    "    fish_population = Counter(fish)\n",
    "    for day in range(n):\n",
    "        fish_population = simulate_day(fish_population)\n",
    "    return sum(fish_population.values())\n",
    "\n",
    "def simulate_day(fish):\n",
    "    new_population = Counter()\n",
    "    for f in range(1, 9):\n",
    "        new_population[f-1] = fish[f]\n",
    "    new_population[6] += fish[0]\n",
    "    new_population[8] = fish[0]\n",
    "    return new_population\n",
    "\n",
    "assert simulate_lanternfish([*map(int, test6_1_input.split(','))], 18) == test6_1_output1\n",
    "assert simulate_lanternfish([*map(int, test6_1_input.split(','))]) == test6_1_output2\n",
    "\n",
    "\n",
    "input6 = data(6,int,sep=',')\n",
    "\n",
    "simulate_lanternfish(input6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-solomon",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "atmospheric-software",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1682576647495"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test6_2_output = 26984457539\n",
    "\n",
    "assert simulate_lanternfish([*map(int, test6_1_input.split(','))], 256) == test6_2_output\n",
    "\n",
    "simulate_lanternfish(input6, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-emperor",
   "metadata": {},
   "source": [
    "# Day 7: The Treachery of Whales\n",
    "\n",
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "enclosed-words",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347509"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test7_1_input = '16,1,2,0,4,2,7,1,2,14'\n",
    "\n",
    "test7_1_output = 37\n",
    "\n",
    "def minimum_fuel_cost(crabs) -> int:\n",
    "    cost = 0\n",
    "    target = median(crabs)\n",
    "    for crab in crabs:\n",
    "        cost += abs(crab - target)\n",
    "    return int(cost)\n",
    "\n",
    "assert minimum_fuel_cost([*map(int ,test7_1_input.split(','))]) == test7_1_output\n",
    "\n",
    "input7 = data(7,int,sep=',')\n",
    "\n",
    "minimum_fuel_cost(input7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-panic",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "european-generic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98257206"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test7_2_output = 168\n",
    "\n",
    "def minimum_fuel_cost2(crabs) -> int:\n",
    "    cost_floor = 0\n",
    "    cost_ceil = 0\n",
    "    target_mean_floor = int(floor(mean(crabs)))\n",
    "    target_mean_ceil = int(ceil(mean(crabs)))\n",
    "    \n",
    "    for crab in crabs:\n",
    "        cost_floor += (abs(crab - target_mean_floor)) * (abs(crab - target_mean_floor)+1) / 2\n",
    "        cost_ceil += (abs(crab - target_mean_ceil)) * (abs(crab - target_mean_ceil)+1) / 2\n",
    "    return int(min(cost_floor, cost_ceil))\n",
    "\n",
    "assert minimum_fuel_cost2([*map(int ,test7_1_input.split(','))]) == test7_2_output\n",
    "\n",
    "input7 = data(7,int,sep=',')\n",
    "\n",
    "minimum_fuel_cost2(input7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-honor",
   "metadata": {},
   "source": [
    "# Day 8: Seven Segment Search\n",
    "\n",
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "demanding-stand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test8_1_input = '''be cfbegad cbdgef fgaecd cgeb fdcge agebfd fecdb fabcd edb | fdgacbe cefdb cefbgd gcbe\n",
    "edbfga begcd cbg gc gcadebf fbgde acbgfd abcde gfcbed gfec | fcgedb cgb dgebacf gc\n",
    "fgaebd cg bdaec gdafb agbcfd gdcbef bgcad gfac gcb cdgabef | cg cg fdcagb cbg\n",
    "fbegcd cbd adcefb dageb afcb bc aefdc ecdab fgdeca fcdbega | efabcd cedba gadfec cb\n",
    "aecbfdg fbg gf bafeg dbefa fcge gcbea fcaegb dgceab fcbdga | gecf egdcabf bgf bfgea\n",
    "fgeab ca afcebg bdacfeg cfaedg gcfdb baec bfadeg bafgc acf | gebdcfa ecba ca fadegcb\n",
    "dbcfg fgd bdegcaf fgec aegbdf ecdfab fbedc dacgb gdcebf gf | cefg dcbef fcge gbcadfe\n",
    "bdfegc cbegaf gecbf dfcage bdacg ed bedf ced adcbefg gebcd | ed bcgafe cdgba cbgef\n",
    "egadfb cdbfeg cegd fecab cgb gbdefca cg fgcdab egfdb bfceg | gbdfcae bgc cg cgb\n",
    "gcafb gcf dcaebfg ecagb gf abcdeg gaef cafbge fdbac fegbdc | fgae cfgab fg bagce'''\n",
    "\n",
    "test8_1_output = 26\n",
    "\n",
    "#def parse_seven_segment(line):\n",
    "#    line.replace('| ', '')\n",
    "#    return line.split()\n",
    "\n",
    "def parse_seven_segment(line):\n",
    "    line.strip()\n",
    "    return line.split('|')\n",
    "\n",
    "def count_unique_digits(segments) -> int:\n",
    "    count = 0\n",
    "    for segment in segments:\n",
    "        for digit in segment[1].split():\n",
    "            if len(digit) <= 4 or len(digit) == 7:\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "assert count_unique_digits([*map(parse_seven_segment, test8_1_input.split('\\n'))]) == test8_1_output\n",
    "\n",
    "input8 = data(8, parse_seven_segment)\n",
    "\n",
    "count_unique_digits(input8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-strengthening",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "amended-notification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "983030"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test8_2_output= 61229\n",
    "\n",
    "def occurence_counter(s):\n",
    "    return Counter(list(s.replace(\" \", \"\")))\n",
    "\n",
    "def occurence_pattern(s, ctr):\n",
    "    return tuple(sorted([ctr[x] for x in s]))\n",
    "\n",
    "canonical_pattern = \"abcefg cf acdeg acdfg bdcf abdfg abdefg acf abcdefg abcdfg\"\n",
    "canonical_dict = occurence_counter(canonical_pattern)\n",
    "\n",
    "translator = {}\n",
    "for i, x in enumerate(canonical_pattern.split(\" \")):\n",
    "    translator[occurence_pattern(x, canonical_dict)] = i\n",
    "\n",
    "def process_line(ls):\n",
    "    outputs = ls[1].strip()\n",
    "    occ_dict = occurence_counter(ls[0])\n",
    "    return [translator[occurence_pattern(x, occ_dict)] for x in outputs.split(\" \")]\n",
    "\n",
    "def count_all_digits(segments) -> int:\n",
    "    count = 0\n",
    "    for segment in segments:\n",
    "        p = process_line(segment)\n",
    "        count += int(\"\".join([str(x) for x in p]))\n",
    "    return count\n",
    "\n",
    "assert count_all_digits([*map(parse_seven_segment, test8_1_input.split('\\n'))]) == test8_2_output\n",
    "\n",
    "input8 = data(8, parse_seven_segment)\n",
    "\n",
    "count_all_digits(input8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guided-abortion",
   "metadata": {},
   "source": [
    "# Day 9: Smoke Basin\n",
    "\n",
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "delayed-maker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "425"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test9_1_input = '''2199943210\n",
    "3987894921\n",
    "9856789892\n",
    "8767896789\n",
    "9899965678'''\n",
    "\n",
    "test9_1_output = 15\n",
    "\n",
    "def find_lowpoints(heightmap) -> int:\n",
    "    Grid = []\n",
    "    for line in heightmap:\n",
    "        Grid.append([int(x) for x in line])\n",
    "    rows = len(Grid)\n",
    "    cols = len(Grid[0])\n",
    "    row_deltas = [-1,0,1,0]\n",
    "    col_deltas = [0,1,0,-1]\n",
    "    riskscore = 0\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            lowpoint = True\n",
    "            for delta in range(len(row_deltas)):\n",
    "                rr = r + row_deltas[delta]\n",
    "                cc = c + col_deltas[delta]\n",
    "                if 0<=rr<rows and 0<=cc<cols and Grid[rr][cc]<=Grid[r][c]:\n",
    "                    lowpoint = False\n",
    "            if lowpoint:\n",
    "                riskscore += Grid[r][c]+1\n",
    "    return riskscore\n",
    "\n",
    "assert find_lowpoints(test9_1_input.split('\\n')) == test9_1_output\n",
    "\n",
    "input9 = data(9)\n",
    "\n",
    "find_lowpoints(input9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-experiment",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "micro-louisville",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1135260"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test9_2_output = 1134\n",
    "\n",
    "def find_basins(heightmap) -> int:\n",
    "    Grid = []\n",
    "    for line in heightmap:\n",
    "        Grid.append([int(x) for x in line])\n",
    "    rows = len(Grid)\n",
    "    cols = len(Grid[0])\n",
    "    row_deltas = [-1,0,1,0]\n",
    "    col_deltas = [0,1,0,-1]\n",
    "    basins = []\n",
    "    seen = set()\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            if (r,c) not in seen and Grid[r][c]!=9:\n",
    "                size = 0\n",
    "                Q = deque()\n",
    "                Q.append((r,c))\n",
    "                while Q:\n",
    "                    (r, c) = Q.popleft()\n",
    "                    if (r, c) in seen:\n",
    "                        continue\n",
    "                    seen.add((r,c))\n",
    "                    size += 1\n",
    "                    for delta in range(len(row_deltas)):\n",
    "                        rr = r+row_deltas[delta]\n",
    "                        cc = c+col_deltas[delta]\n",
    "                        if 0<=rr<rows and 0<=cc<cols and Grid[rr][cc]!=9:\n",
    "                            Q.append((rr,cc))\n",
    "                basins.append(size)\n",
    "    basins.sort()                \n",
    "    return basins[-1] * basins[-2] * basins[-3]\n",
    "\n",
    "assert find_basins(test9_1_input.split('\\n')) == test9_2_output\n",
    "\n",
    "input9 = data(9)\n",
    "\n",
    "find_basins(input9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-rogers",
   "metadata": {},
   "source": [
    "# Day 10: Syntax Scoring\n",
    "\n",
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "accessory-sunrise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "462693"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test10_1_input = '''[({(<(())[]>[[{[]{<()<>>\n",
    "[(()[<>])]({[<{<<[]>>(\n",
    "{([(<{}[<>[]}>{[]{[(<()>\n",
    "(((({<>}<{<{<>}{[]{[]{}\n",
    "[[<[([]))<([[{}[[()]]]\n",
    "[{[{({}]{}}([{[{{{}}([]\n",
    "{<[[]]>}<{[{[{[]{()[[[]\n",
    "[<(<(<(<{}))><([]([]()\n",
    "<{([([[(<>()){}]>(<<{{\n",
    "<{([{{}}[<[[[<>{}]]]>[]]'''\n",
    "\n",
    "test10_1_output = 26397\n",
    "\n",
    "match = {')': '(', ']': '[', '}': '{', '>': '<'}\n",
    "\n",
    "penalty = {')': 3, ']': 57, '}': 1197, '>': 25137}\n",
    "\n",
    "def syntax_error_score(navigation_lines) -> int:\n",
    "    error_score = 0\n",
    "    for line in navigation_lines:\n",
    "        stack = []\n",
    "        for symbol in line:\n",
    "            if symbol in set('([<{'):\n",
    "                stack.append(symbol)\n",
    "            if symbol in set('}])>'):\n",
    "                previous = stack.pop()\n",
    "                if match[symbol] == previous:\n",
    "                    continue\n",
    "                else:\n",
    "                    error_score += penalty[symbol]\n",
    "    return error_score\n",
    "\n",
    "assert syntax_error_score(test10_1_input.split('\\n')) == test10_1_output\n",
    "\n",
    "input10 = data(10)\n",
    "\n",
    "syntax_error_score(input10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-ribbon",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "detailed-circus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3094671161"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test10_2_output = 288957\n",
    "\n",
    "score = {'(': 1, '[': 2, '{': 3, '<':4}\n",
    "\n",
    "def auto_complete_score(navigation_lines) -> int:\n",
    "    completion_scores = []\n",
    "    for line in navigation_lines:\n",
    "        stack = []\n",
    "        for symbol in line:\n",
    "            if symbol in set('([<{'):\n",
    "                stack.append(symbol)\n",
    "            elif not stack or stack.pop() != match[symbol]:\n",
    "                stack = None\n",
    "                break\n",
    "                \n",
    "        if stack:\n",
    "            subtotal = 0\n",
    "\n",
    "            for symbol in stack[::-1]:\n",
    "                subtotal = 5 * subtotal + score[symbol]\n",
    "\n",
    "            completion_scores.append(subtotal)\n",
    "                    \n",
    "    \n",
    "    return median(completion_scores)\n",
    "\n",
    "assert auto_complete_score(test10_1_input.split('\\n')) == test10_2_output\n",
    "\n",
    "input10 = data(10)\n",
    "\n",
    "auto_complete_score(input10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-proposal",
   "metadata": {},
   "source": [
    "# Day 11: Dumbo Octopus\n",
    "\n",
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "interpreted-colombia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1599"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test11_1_input = '''5483143223\n",
    "2745854711\n",
    "5264556173\n",
    "6141336146\n",
    "6357385478\n",
    "4167524645\n",
    "2176841721\n",
    "6882881134\n",
    "4846848554\n",
    "5283751526'''\n",
    "\n",
    "test11_1_output = 1656\n",
    "\n",
    "rows = 10\n",
    "cols = 10\n",
    "\n",
    "def flash(r, c):\n",
    "    global count\n",
    "    global Grid\n",
    "    count += 1\n",
    "    Grid[r][c] = -1\n",
    "    for dr in [-1,0,1]:\n",
    "        for dc in [-1,0,1]:\n",
    "            rr = r+dr\n",
    "            cc = c+dc\n",
    "            if 0<=rr<rows and 0<=cc<cols and Grid[rr][cc]!=-1:\n",
    "                Grid[rr][cc] += 1\n",
    "                if Grid[rr][cc] >= 10:\n",
    "                    flash(rr,cc)\n",
    "\n",
    "\n",
    "\n",
    "def count_flashes(energy_levels, n=100) -> int:\n",
    "    global count\n",
    "    global Grid\n",
    "    Grid = []\n",
    "    for line in energy_levels:\n",
    "        Grid.append([int(x) for x in line])\n",
    "    rows = len(Grid)\n",
    "    cols = len(Grid[0])\n",
    "    count = 0\n",
    "\n",
    "    for step in range(n):\n",
    "        for r in range(rows):\n",
    "            for c in range(cols):\n",
    "                Grid[r][c] += 1\n",
    "        for r in range(rows):\n",
    "            for c in range(cols):\n",
    "                if Grid[r][c] == 10:\n",
    "                    flash(r,c)\n",
    "        for r in range(rows):\n",
    "            for c in range(cols):\n",
    "                if Grid[r][c] == -1:\n",
    "                    Grid[r][c] = 0\n",
    "                \n",
    "    return(count)\n",
    "\n",
    "assert count_flashes(test11_1_input.split()) == test11_1_output\n",
    "    \n",
    "input11 = data(11)\n",
    "\n",
    "count_flashes(input11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-layer",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "upper-supervision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test11_2_output = 195\n",
    "\n",
    "rows = 10\n",
    "cols = 10\n",
    "\n",
    "def flash(r, c):\n",
    "    global count\n",
    "    global Grid\n",
    "    count += 1\n",
    "    Grid[r][c] = -1\n",
    "    for dr in [-1,0,1]:\n",
    "        for dc in [-1,0,1]:\n",
    "            rr = r+dr\n",
    "            cc = c+dc\n",
    "            if 0<=rr<rows and 0<=cc<cols and Grid[rr][cc]!=-1:\n",
    "                Grid[rr][cc] += 1\n",
    "                if Grid[rr][cc] >= 10:\n",
    "                    flash(rr,cc)\n",
    "\n",
    "def synchronized_flashes(energy_levels) -> int:\n",
    "    global Grid\n",
    "    Grid = []\n",
    "    for line in energy_levels:\n",
    "        Grid.append([int(x) for x in line])\n",
    "    step = 0\n",
    "    while True:\n",
    "        step += 1\n",
    "        for r in range(rows):\n",
    "            for c in range(cols):\n",
    "                Grid[r][c] += 1\n",
    "        for r in range(rows):\n",
    "            for c in range(cols):\n",
    "                if Grid[r][c] == 10:\n",
    "                    flash(r, c)\n",
    "        done = True\n",
    "        for r in range(rows):\n",
    "            for c in range(cols):\n",
    "                if Grid[r][c] == -1:\n",
    "                    Grid[r][c] = 0\n",
    "                else:\n",
    "                    done = False\n",
    "        if done:\n",
    "            return step\n",
    "        \n",
    "assert synchronized_flashes(test11_1_input.split()) == test11_2_output\n",
    "\n",
    "input11 = data(11)\n",
    "\n",
    "synchronized_flashes(input11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-harvest",
   "metadata": {},
   "source": [
    "# Day 12: Passage Pathing\n",
    "\n",
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "respiratory-rental",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5212"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test12_1_input1 = '''start-A\n",
    "start-b\n",
    "A-c\n",
    "A-b\n",
    "b-d\n",
    "A-end\n",
    "b-end'''\n",
    "\n",
    "test12_1_input2 = '''dc-end\n",
    "HN-start\n",
    "start-kj\n",
    "dc-start\n",
    "dc-HN\n",
    "LN-dc\n",
    "HN-end\n",
    "kj-sa\n",
    "kj-HN\n",
    "kj-dc'''\n",
    "\n",
    "test12_1_input3 = '''fs-end\n",
    "he-DX\n",
    "fs-he\n",
    "start-DX\n",
    "pj-DX\n",
    "end-zg\n",
    "zg-sl\n",
    "zg-pj\n",
    "pj-he\n",
    "RW-he\n",
    "fs-DX\n",
    "pj-RW\n",
    "zg-RW\n",
    "start-pj\n",
    "he-WI\n",
    "zg-he\n",
    "pj-fs\n",
    "start-RW'''\n",
    "\n",
    "test12_1_output1 = 10\n",
    "test12_1_output2 = 19\n",
    "test12_1_output3 = 226\n",
    "\n",
    "def parse_edges(line):\n",
    "    return line.split('-')\n",
    "\n",
    "def count_paths(edges, seen=[], cave='start') -> int:\n",
    "    global neighbours\n",
    "    neighbours = defaultdict(list)\n",
    "    for edge in edges:\n",
    "        neighbours[edge[0]] += [edge[1]]\n",
    "        neighbours[edge[1]] += [edge[0]]\n",
    "    return count(seen, cave)\n",
    "\n",
    "def count(seen=[], cave='start'):\n",
    "    if cave == 'end': return 1\n",
    "    if cave in seen:\n",
    "        if cave == 'start': return 0\n",
    "        if cave.islower():\n",
    "            return 0\n",
    "    return sum(count(seen+[cave], n) for n in neighbours[cave])\n",
    "\n",
    "assert count_paths([*map(parse_edges, test12_1_input1.split())]) == test12_1_output1\n",
    "assert count_paths([*map(parse_edges, test12_1_input2.split())]) == test12_1_output2\n",
    "assert count_paths([*map(parse_edges, test12_1_input3.split())]) == test12_1_output3\n",
    "\n",
    "input12 = data(12, parse_edges)\n",
    "\n",
    "count_paths(input12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-confirmation",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "apparent-durham",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134862"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test12_2_output1 = 36\n",
    "test12_2_output2 = 103\n",
    "test12_2_output3 = 3509\n",
    "\n",
    "def parse_edges(line):\n",
    "    return line.split('-')\n",
    "\n",
    "def count_paths2(edges, seen=[], cave='start') -> int:\n",
    "    global neighbours\n",
    "    neighbours = defaultdict(list)\n",
    "    for edge in edges:\n",
    "        neighbours[edge[0]] += [edge[1]]\n",
    "        neighbours[edge[1]] += [edge[0]]\n",
    "    return count(part=2)\n",
    "\n",
    "def count(part, seen=[], cave='start'):\n",
    "    if cave == 'end': return 1\n",
    "    if cave in seen:\n",
    "        if cave == 'start': return 0\n",
    "        if cave.islower():\n",
    "            if part == 1: return 0\n",
    "            else: part = 1\n",
    "    return sum(count(part, seen+[cave], n)\n",
    "                for n in neighbours[cave])\n",
    "\n",
    "assert count_paths2([*map(parse_edges, test12_1_input1.split())]) == test12_2_output1\n",
    "assert count_paths2([*map(parse_edges, test12_1_input2.split())]) == test12_2_output2\n",
    "assert count_paths2([*map(parse_edges, test12_1_input3.split())]) == test12_2_output3\n",
    "\n",
    "input12 = data(12, parse_edges)\n",
    "\n",
    "count_paths2(input12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-dimension",
   "metadata": {},
   "source": [
    "# Day 13: Transparent Origami\n",
    "\n",
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "blocked-professional",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "755"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test13_1_input = '''6,10\n",
    "0,14\n",
    "9,10\n",
    "0,3\n",
    "10,4\n",
    "4,11\n",
    "6,0\n",
    "6,12\n",
    "4,1\n",
    "0,13\n",
    "10,12\n",
    "3,4\n",
    "3,0\n",
    "8,4\n",
    "1,10\n",
    "2,14\n",
    "8,10\n",
    "9,0\n",
    "\n",
    "fold along y=7\n",
    "fold along x=5'''\n",
    "\n",
    "test13_1_output = 17\n",
    "\n",
    "def count_points_after_fold(points, folds) -> int:\n",
    "    overlapping = 0\n",
    "    target = folds[0]\n",
    "    if target[0] == 'x':\n",
    "        for p in points:\n",
    "            if int(p[0]) > int(target[1:]):\n",
    "                distance = abs(int(target[1:]) - int(p[0]))\n",
    "                if [str((int(p[0]) - 2 * distance)), p[1]] in points:\n",
    "                    overlapping += 1\n",
    "    else:\n",
    "        for p in points:\n",
    "            if int(p[1]) > int(target[1:]):\n",
    "                distance = abs(int(target[1:]) - int(p[1]))\n",
    "                if [p[0], str((int(p[1]) - 2 * distance))] in points:\n",
    "                    overlapping += 1\n",
    "    return len(points) - overlapping\n",
    "\n",
    "test_points = [x.split(',') for x in test13_1_input.split('\\n\\n')[0].split('\\n')]\n",
    "test_folds = [y[0][-1] + y[1] for y in [x.split('=') for x in test13_1_input.split('\\n\\n')[1].split('\\n')]]\n",
    "\n",
    "assert count_points_after_fold(test_points, test_folds) == test13_1_output\n",
    "\n",
    "input13 = data(13, sep='\\n\\n')\n",
    "points = [x.split(',') for x in input13[0].split('\\n')]\n",
    "folds = [y[0][-1] + y[1] for y in [x.split('=') for x in input13[1].split('\\n')]]\n",
    "\n",
    "count_points_after_fold(points, folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-thousand",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "fitting-engineering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###..#....#..#...##.###..###...##...##.\n",
      "#..#.#....#.#.....#.#..#.#..#.#..#.#..#\n",
      "###..#....##......#.#..#.###..#..#.#...\n",
      "#..#.#....#.#.....#.###..#..#.####.#.##\n",
      "#..#.#....#.#..#..#.#.#..#..#.#..#.#..#\n",
      "###..####.#..#..##..#..#.###..#..#..###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Point = Tuple[int, int]\n",
    "Grid = Set[Point]\n",
    "\n",
    "def parse_folds(folds: List[str]) -> List[Tuple[bool, int]]:\n",
    "    result: List[Tuple[bool, int]] = []\n",
    "    for fold in folds:\n",
    "        fold_desc = re.search(r\"(x|y)(\\d+)\", fold)\n",
    "        assert fold_desc\n",
    "        result.append((fold_desc.group(1) == \"y\", int(fold_desc.group(2))))\n",
    "\n",
    "    return result\n",
    "\n",
    "def print_grid_after_folds(points, folds):\n",
    "    dots: Grid = {\n",
    "        cast(Point, tuple(map(int, point))) for point in points\n",
    "    }\n",
    "    folds = parse_folds(folds)\n",
    "    for fold_ins in folds:\n",
    "        dots = fold_grid(dots, *fold_ins)\n",
    "    print()\n",
    "    print_grid(dots)\n",
    "    return\n",
    "\n",
    "def print_grid(dots: Grid):\n",
    "    max_x = max(x[0] for x in dots)\n",
    "    max_y = max(y[1] for y in dots)\n",
    "\n",
    "    for y in range(max_y + 1):\n",
    "        for x in range(max_x + 1):\n",
    "            print(\"#\" if (x, y) in dots else \".\", end=\"\")\n",
    "        print() # newline!\n",
    "    print() # space after the print\n",
    "    \n",
    "def fold_grid(dots: Grid, horiz: bool, val: int) -> Grid:\n",
    "    result: Grid = set()\n",
    "    modified_index, same_index = (1, 0) if horiz else (0, 1)\n",
    "\n",
    "    for p in dots:\n",
    "        # if being folded onto, no change\n",
    "        if p[modified_index] < val:\n",
    "            result.add(p)\n",
    "            continue\n",
    "\n",
    "        updated_point = [-1, -1]\n",
    "        # one half of the points is unmodified\n",
    "        updated_point[same_index] = p[same_index]\n",
    "\n",
    "        # the other half changes based on its distance to the line\n",
    "        updated_point[modified_index] = 2 * val - p[modified_index]\n",
    "\n",
    "        result.add(cast(Point, tuple(updated_point)))\n",
    "\n",
    "    return result\n",
    "\n",
    "print_grid_after_folds(points, folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-pitch",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
